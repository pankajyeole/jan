{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bd32bc0",
   "metadata": {},
   "source": [
    "# Student Placement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151c60f5",
   "metadata": {},
   "source": [
    "## Import Labrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf12e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,r2_score,classification_report\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecb0327e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>iq</th>\n",
       "      <th>profile_score</th>\n",
       "      <th>placed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.97</td>\n",
       "      <td>106</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.83</td>\n",
       "      <td>113</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.60</td>\n",
       "      <td>110</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.54</td>\n",
       "      <td>113</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.84</td>\n",
       "      <td>102</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>6.44</td>\n",
       "      <td>107</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>6.09</td>\n",
       "      <td>108</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>7.68</td>\n",
       "      <td>101</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>7.00</td>\n",
       "      <td>90</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>4.79</td>\n",
       "      <td>118</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cgpa   iq  profile_score  placed\n",
       "0    5.97  106             61       0\n",
       "1    6.83  113             77       0\n",
       "2    6.60  110             61       0\n",
       "3    5.54  113             68       0\n",
       "4    6.84  102             67       0\n",
       "..    ...  ...            ...     ...\n",
       "295  6.44  107             54       0\n",
       "296  6.09  108             52       0\n",
       "297  7.68  101             70       1\n",
       "298  7.00   90             28       1\n",
       "299  4.79  118             70       0\n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('students_placement.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1e9120f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   cgpa           300 non-null    float64\n",
      " 1   iq             300 non-null    int64  \n",
      " 2   profile_score  300 non-null    int64  \n",
      " 3   placed         300 non-null    int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 9.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebd25003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    152\n",
       "0    148\n",
       "Name: placed, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['placed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0806a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "295    0\n",
       "296    0\n",
       "297    1\n",
       "298    1\n",
       "299    0\n",
       "Name: placed, Length: 300, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=df.drop(['placed'],axis=1)\n",
    "y=df['placed']\n",
    "x\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2795b5e",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aee78a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>iq</th>\n",
       "      <th>profile_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.51</td>\n",
       "      <td>112</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>8.41</td>\n",
       "      <td>100</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>8.25</td>\n",
       "      <td>92</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>7.51</td>\n",
       "      <td>90</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>6.97</td>\n",
       "      <td>101</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>6.17</td>\n",
       "      <td>115</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>6.45</td>\n",
       "      <td>107</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>5.33</td>\n",
       "      <td>103</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>6.86</td>\n",
       "      <td>110</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>5.19</td>\n",
       "      <td>116</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>6.49</td>\n",
       "      <td>108</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>6.34</td>\n",
       "      <td>105</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>8.37</td>\n",
       "      <td>107</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>7.06</td>\n",
       "      <td>93</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>8.29</td>\n",
       "      <td>89</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7.73</td>\n",
       "      <td>90</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>8.52</td>\n",
       "      <td>99</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>5.80</td>\n",
       "      <td>107</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>6.04</td>\n",
       "      <td>104</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>7.60</td>\n",
       "      <td>103</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.56</td>\n",
       "      <td>104</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>7.00</td>\n",
       "      <td>104</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>6.69</td>\n",
       "      <td>93</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>7.50</td>\n",
       "      <td>102</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>6.02</td>\n",
       "      <td>107</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>6.02</td>\n",
       "      <td>121</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>8.80</td>\n",
       "      <td>83</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>4.97</td>\n",
       "      <td>116</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>9.05</td>\n",
       "      <td>94</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.99</td>\n",
       "      <td>116</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>8.09</td>\n",
       "      <td>97</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>5.70</td>\n",
       "      <td>118</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.19</td>\n",
       "      <td>97</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>6.69</td>\n",
       "      <td>104</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>6.32</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>7.00</td>\n",
       "      <td>90</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>6.89</td>\n",
       "      <td>104</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>7.27</td>\n",
       "      <td>91</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>6.02</td>\n",
       "      <td>107</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>6.99</td>\n",
       "      <td>94</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>5.80</td>\n",
       "      <td>116</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>5.13</td>\n",
       "      <td>114</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>5.51</td>\n",
       "      <td>114</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>8.35</td>\n",
       "      <td>98</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>5.34</td>\n",
       "      <td>104</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>5.67</td>\n",
       "      <td>111</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>7.54</td>\n",
       "      <td>96</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>5.61</td>\n",
       "      <td>108</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>7.93</td>\n",
       "      <td>94</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.64</td>\n",
       "      <td>102</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>8.13</td>\n",
       "      <td>91</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>5.67</td>\n",
       "      <td>112</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>6.98</td>\n",
       "      <td>105</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>5.54</td>\n",
       "      <td>118</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>6.85</td>\n",
       "      <td>102</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>7.97</td>\n",
       "      <td>96</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>7.12</td>\n",
       "      <td>107</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5.29</td>\n",
       "      <td>103</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>6.62</td>\n",
       "      <td>96</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>5.31</td>\n",
       "      <td>116</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cgpa   iq  profile_score\n",
       "24   5.51  112             51\n",
       "65   8.41  100             58\n",
       "113  8.25   92             67\n",
       "261  7.51   90             69\n",
       "188  6.97  101             68\n",
       "181  6.17  115             52\n",
       "59   6.45  107             63\n",
       "87   5.33  103             75\n",
       "293  6.86  110             63\n",
       "277  5.19  116             86\n",
       "244  6.49  108             45\n",
       "43   6.34  105             62\n",
       "193  8.37  107             58\n",
       "284  7.06   93             44\n",
       "238  8.29   89             70\n",
       "26   7.73   90             68\n",
       "245  8.52   99             58\n",
       "214  5.80  107             92\n",
       "189  6.04  104             30\n",
       "281  7.60  103             64\n",
       "52   6.56  104             77\n",
       "215  7.00  104             48\n",
       "130  6.69   93             72\n",
       "64   7.50  102             59\n",
       "164  6.02  107             69\n",
       "70   6.02  121             27\n",
       "138  8.80   83             62\n",
       "202  4.97  116             72\n",
       "230  9.05   94             67\n",
       "132  6.99  116             63\n",
       "47   8.09   97             80\n",
       "151  5.70  118             65\n",
       "25   7.19   97             47\n",
       "183  6.69  104             74\n",
       "197  6.32  107             68\n",
       "298  7.00   90             28\n",
       "276  6.89  104             81\n",
       "98   7.27   91             70\n",
       "231  6.02  107             74\n",
       "76   6.99   94             73\n",
       "129  5.80  116             50\n",
       "167  5.13  114             83\n",
       "270  5.51  114             51\n",
       "100  8.35   98             71\n",
       "191  5.34  104             98\n",
       "199  5.67  111             69\n",
       "139  7.54   96             71\n",
       "106  5.61  108             74\n",
       "36   7.93   94             53\n",
       "10   7.64  102             51\n",
       "273  8.13   91             35\n",
       "111  5.67  112             67\n",
       "286  6.98  105             54\n",
       "119  5.54  118             60\n",
       "280  6.85  102             67\n",
       "195  7.97   96             76\n",
       "237  7.12  107             62\n",
       "80   5.29  103             83\n",
       "172  6.62   96             37\n",
       "56   5.31  116             51"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test =train_test_split(x,y,test_size=0.2,random_state=10,)\n",
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca19283c",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1888855e",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74bdeef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegressionCV()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegressionCV</label><div class=\"sk-toggleable__content\"><pre>LogisticRegressionCV()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegressionCV()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_model=LogisticRegressionCV()\n",
    "lg_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77666b19",
   "metadata": {},
   "source": [
    "## Evalution Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8243b110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      " [[29  3]\n",
      " [ 5 23]]\n",
      "accuracy score\n",
      " 0.8666666666666667\n",
      "classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88        32\n",
      "           1       0.88      0.82      0.85        28\n",
      "\n",
      "    accuracy                           0.87        60\n",
      "   macro avg       0.87      0.86      0.87        60\n",
      "weighted avg       0.87      0.87      0.87        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#accuracy on testing data\n",
    "\n",
    "y_pred=lg_model.predict(x_test)\n",
    "\n",
    "conf_matrix=confusion_matrix(y_test,y_pred)\n",
    "print(\"confusion matrix\\n\",conf_matrix)\n",
    "\n",
    "acc_scroe=accuracy_score(y_test,y_pred)\n",
    "print(\"accuracy score\\n\",acc_scroe)\n",
    "\n",
    "clss_report=classification_report(y_test,y_pred)\n",
    "print(\"classification report\\n\",clss_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c376c68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      " [[103  13]\n",
      " [ 16 108]]\n",
      "accuracy score\n",
      " 0.8791666666666667\n",
      "classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       116\n",
      "           1       0.89      0.87      0.88       124\n",
      "\n",
      "    accuracy                           0.88       240\n",
      "   macro avg       0.88      0.88      0.88       240\n",
      "weighted avg       0.88      0.88      0.88       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#accuracy on trainig data\n",
    "\n",
    "y_pred_train=lg_model.predict(x_train)\n",
    "\n",
    "conf_matrix=confusion_matrix(y_train,y_pred_train)\n",
    "print(\"confusion matrix\\n\",conf_matrix)\n",
    "\n",
    "acc_scroe=accuracy_score(y_train,y_pred_train)\n",
    "print(\"accuracy score\\n\",acc_scroe)\n",
    "\n",
    "clss_report=classification_report(y_train,y_pred_train)\n",
    "print(\"classification report\\n\",clss_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1834cc5d",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d250e701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rf_model=RandomForestClassifier()\n",
    "Rf_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e22a227c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      " [[27  5]\n",
      " [ 5 23]]\n",
      "accuracy score\n",
      " 0.8333333333333334\n",
      "classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84        32\n",
      "           1       0.82      0.82      0.82        28\n",
      "\n",
      "    accuracy                           0.83        60\n",
      "   macro avg       0.83      0.83      0.83        60\n",
      "weighted avg       0.83      0.83      0.83        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#accuracy on testing data\n",
    "\n",
    "y_pred=Rf_model.predict(x_test)\n",
    "\n",
    "conf_matrix=confusion_matrix(y_test,y_pred)\n",
    "print(\"confusion matrix\\n\",conf_matrix)\n",
    "\n",
    "acc_scroe=accuracy_score(y_test,y_pred)\n",
    "print(\"accuracy score\\n\",acc_scroe)\n",
    "\n",
    "clss_report=classification_report(y_test,y_pred)\n",
    "print(\"classification report\\n\",clss_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f989668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      " [[116   0]\n",
      " [  0 124]]\n",
      "accuracy score\n",
      " 1.0\n",
      "classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       116\n",
      "           1       1.00      1.00      1.00       124\n",
      "\n",
      "    accuracy                           1.00       240\n",
      "   macro avg       1.00      1.00      1.00       240\n",
      "weighted avg       1.00      1.00      1.00       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#accuracy on trainig data\n",
    "\n",
    "y_pred_train=Rf_model.predict(x_train)\n",
    "\n",
    "conf_matrix=confusion_matrix(y_train,y_pred_train)\n",
    "print(\"confusion matrix\\n\",conf_matrix)\n",
    "\n",
    "acc_scroe=accuracy_score(y_train,y_pred_train)\n",
    "print(\"accuracy score\\n\",acc_scroe)\n",
    "\n",
    "clss_report=classification_report(y_train,y_pred_train)\n",
    "print(\"classification report\\n\",clss_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75ae35f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('model.pkl','wb')as f:\n",
    "    pickle.dump(lg_model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9c2057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
